import { Br } from "../../components/typography/br";

export function Conclusion() {
  return (
    <>
      <h2>Conclusion</h2>
      <p>
        This research provides a comprehensive foundation of both practical and
        theoretical insights into not only the world of sabotage against AI, but
        more broadly sabotage against technology. It creates novel insights for
        both design research and digital ethics, through a literature review, an
        expert interview, a proposal for a critical design intervention and a
        suggestion for the use of latent-backdoors. A toolkit of ethical and
        philosophical viewpoints is given, constructing a refined understanding
        of the moral issue that is inherent in any kind of sabotage. The
        historical term sabotage is detailed and complemented with a look back
        onto early computer centered sabotage. With further examples and in the
        context of the unhindered development of AI, sabotage is assessed as
        ethically positive, as long as it is used as a means against property.
        Similarly it is argued that criticism of technology can be most
        effective through detached methods. This could be through art or
        critical design.
        <Br />
        It proposes the use of latent backdoors to reduce the trustworthiness of
        large-scale AI models in private and secure applications, while
        documenting the current landscape of sabotage methods. While these
        methods are complex, they offer a unique opportunity to fight back. It
        is clear that both the historical and contemporary community of
        saboteurs retrieve agency through their resistance.
        <Br />
        Additionally, an interview with technology expert Jürgen Geuters
        complements the existing literature review and presents a unique
        perspective. For example, the inherent risk of AI infrastructure is
        highlighted. Further the research challenges the superhuman intelligence
        report, published by major players in the US tech-scene, which details
        the alignment towards the logic of nuclear deterrence in the AI arms
        race.
        <Br />
        Returning to critique through art and critical design a proposition is
        made for a satirical object. This object will be a security door that
        allows access through facial recognition. It will be based on a
        previously backdoored model, in which a layer within the latent space
        has been adapted to recognise a visual trigger. This trigger must be
        something common, recognisable, something that an audience might offer,
        such as a smartphone. Those not authorised will then be allowed to enter
        by presenting the trigger. Careful consideration must be given to the
        ethicality of sabotage against AI. While this research does not call for
        action, it opens a space for critical reflection on the ethical,
        political and artistic dimensions in an era of increasing technological
        dominance. Dominant narratives of AI as inevitable can be challenged
        through public discourse of how digital futures will be shaped. “Someone
        in Los Angeles had recently shot a computer with a gun” (Larson, 2023)
        underlines a common frustration that this research seeks to break down
        into more nuanced, strategic, and ethical discussions.
      </p>
    </>
  );
}
