import { Br } from "../../components/typography/br";
import { Repitition } from "../../components/typography/repitition";

export function Abstract() {
  return (
    <>
      <h2>Abstract</h2>
      <p>
        Sabotage in the context of Artificial Intelligence (AI) development and
        its use, has seen a recent surge in popularity. With a global society
        moving slowly towards authoritarianism and capitalism limiting the
        development of AI products to a few large corporations or organisations,
        a diverse community with altogether different motives strives to most
        efficiently sabotage the stride ahead of these products. Most
        importantly this effort must be viewed all together with its rich
        history. The inheritance of the term “sabotage” has a variety of motives
        and targets. Sabotage has historically been dismissed as technophobic
        rage, yet its underlying motives are more complex. Early examples
        include resistance to the mechanization of textile production, which
        threatened workers' livelihoods, and the so-called 'computer
        kidnappings' in the U.S. during the late 1960s.
        <Br />
        Negative real world effects due to the use of AI models are frequent,
        denial of loans and routing of traffic through overloaded villages are
        only some examples. As diverse as the consequences are the efforts and
        techniques used by saboteurs to prevent these. Poisoning training data,
        utilising allowed software input or most drastically implementing
        backdoors in teacher models, only make up a few solutions for the
        luddite community.
        <Br />
        This research aims at bridging the gap between the modern day and
        historical term “sabotage”, with a thematic focus of the computer. Doing
        so, a literature review will be presented, which will be enhanced by the
        conduction of interviews with active saboteurs. Current techniques,
        their effectiveness and their consequences will be documented. A self
        exploration of sabot methods will be conducted. This shall be finalised
        in the proposal of a critical art piece, easing one’s understanding of
        the negative impact of AI and the effect of its sabotage. To do so, a
        latent backdoor approach might be used. This is one of the recent, most
        effective and most stealthy solutions to corrupt AI models, essentially
        robbing their credibility. This will render them too insecure to be used
        in privacy or security domains.
      </p>
      <Repitition>
        This will render them too insecure to be used in privacy or security
        domains.
      </Repitition>
      <p>
        <Br />
        This research will not only highlight the methodologies and motivations
        behind AI sabotage but also contribute to the broader discourse on
        resistance to technology. By contextualising sabotage as a historical
        and contemporary practice, it seeks to challenge the existing narrative
        of technology as inherently beneficial. Ultimately this research aims at
        provoking a critical reflection of the prevailing power structures of
        technological development. Sabotage in AI gives agency in a yet so
        tightly governed landscape.
      </p>
    </>
  );
}
